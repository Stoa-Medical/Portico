# Signal Data Model Design Document

## Overview

This document outlines the implementation of a **Signal** data model to support an event‚Äêbased system within the Portico server. A Signal represents any occurrence (scheduled, triggered by a user or agent, or resulting from another Signal) that is used to drive workflow initiation and system monitoring. This replaces the earlier OpenTelemetry-inspired design with a more straightforward approach aligned with the overall Portico MVP plan.

## Background

Portico currently has several key components:
- **Agents** that listen for data and react or initiate actions (see `agents.rs`).
- **Missions** that represent task requests and track execution flow (create `missions.rs`).
- **Runtime Sessions** that manage the execution of steps (see `runtime_sessions.rs`).

The system is built as an event-based architecture where a **Signal** is the core data model used to trigger actions. Rather than using complex OpenTelemetry tracing fields, Signals are keyed on simple identifiers and metadata that allow us to understand the system state and trigger missions.

## Goals

1. **Track System Activity:** Register Signals that capture key events and state changes across components.
2. **Trigger Actions:** Use Signals to drive the creation of Missions and RuntimeSessions.
3. **Improve Observability:** Enable simple logging, debugging, and monitoring through a dedicated Signal log.
4. **Support Both User and Agent Initiatives:** Allow Signals to be generated from user actions, agent activities, or system events.

## Design

### 1. Signal Data Model

We define the core **Signal** struct with the following fields:

- **id:** A unique identifier for the Signal.
- **parent_signal_id:** Optionally links this Signal to a prior Signal.
- **timestamp:** The time the Signal was generated.
- **duration:** Optionally, a duration indicating processing time.
- **name:** A human-readable name or description.
- **signal_type:** An enum describing the type of Signal.
- **status:** The current state of the Signal.
- **attributes:** Arbitrary key-value metadata.
- **resource:** The originator of the Signal (e.g., Agent, User, System, Mission, or Step).
- **child_signals:** Nested signals, if multiple layers of causation need to be tracked.

The data model is implemented as follows:

```rust:server/src/models/signal.rs
/// Core representation of a system Signal.
#[derive(Debug, Serialize, Deserialize)]
pub struct Signal {
    /// Unique identifier for this Signal.
    pub id: String,
    
    /// Optional parent Signal ID that triggered this Signal.
    pub parent_signal_id: Option<String>,
    
    /// Timestamp when the Signal was generated.
    pub timestamp: DateTime<Utc>,
    
    /// Optional duration for which the Signal was active or processed.
    pub duration: Option<Duration>,
    
    /// Human-readable Signal name.
    pub name: String,
    
    /// The type of Signal.
    pub signal_type: SignalType,
    
    /// Current status of the Signal.
    pub status: SignalStatus,
    
    /// Additional metadata in key-value format.
    pub attributes: HashMap<String, Value>,
    
    /// Resource identity indicating the originator of the Signal.
    pub resource: SignalResource,
    
    /// Nested child Signals triggered by this Signal.
    pub child_signals: Vec<Signal>,
}
```

*Note:*  
<!-- Suggestion: Consider extending the `Event` struct by conditionally compiling in extra fields (e.g., an optional trace context) when the `tracing` feature flag is enabled. Also, implement traits such as `TraceEnabled` (to inject trace IDs) and `SpanEnabled` (to support child span additions). -->

```rust
#[derive(Debug, Serialize, Deserialize)]
pub enum SignalType {
    /// A Signal from a scheduled process (e.g., CRON job).
    Scheduled,
    /// A Signal triggered directly by a user.
    UserAction,
    /// A Signal triggered by an Agent.
    AgentAction,
    /// A Signal responding to another Signal.
    Response,
    /// A Signal indicating a system-generated event.
    SystemEvent,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum SignalStatus {
    /// Signal has been initiated.
    Initiated,
    /// Signal is currently in progress.
    InProgress,
    /// Signal has been completed.
    Completed,
    /// Signal processing failed.
    Failed,
    /// Signal was cancelled.
    Cancelled,
}

#[derive(Debug, Serialize, Deserialize)]
pub enum SignalResource {
    /// Signal originated from an Agent (by Agent ID).
    Agent(String),
    /// Signal originated from a User (by User ID).
    User(String),
    /// Signal generated by the System.
    System,
    /// Signal related to a Job (by Job ID).
    Job(String),
    /// Signal related to a Step execution (by Step ID).
    Step(String),
}
```

### 2. Database Schema Updates

To persist Signals, we add a new **signals** table. Below is the proposed schema in HCL:

```hcl:server/db_schema_signals.hcl
table "signals" {
  schema = schema.public
  
  column "id" {
    type = uuid
    default = sql("gen_random_uuid()")
    null = false
  }
  
  column "parent_signal_id" {
    type = uuid
    null = true
  }
  
  column "timestamp" {
    type = timestamptz
    null = false
  }
  
  column "duration_ms" {
    type = bigint
    null = true
  }
  
  column "name" {
    type = text
    null = false
  }
  
  column "signal_type" {
    type = text
    null = false
  }
  
  column "status" {
    type = text
    null = false
  }
  
  column "attributes" {
    type = jsonb
    null = false
  }
  
  column "resource_type" {
    type = text
    null = false
  }
  
  column "resource_id" {
    type = text
    null = false
  }
  
  primary_key {
    columns = [column.id]
  }
  
  index "idx_signals_parent" {
    columns = [column.parent_signal_id]
  }
  
  index "idx_signals_timestamp" {
    columns = [column.timestamp]
  }
}
```

### 3. Integration Points

Signals will integrate with existing components as follows:

1. **Agent Integration**
   - **Signal Generation:** Agents emit Signals when their state changes or execute actions.
   - **Linking:** Agent-initiated Signals can include references to parent Signals for causation analysis.

2. **Mission Integration**
   - **Lifecycle Tracking:** A new Mission is initiated by creating a Signal and is updated as it progresses (e.g., upon initiation, during execution, on success, or error).
   - **Correlations:** Signals from Missions can be linked hierarchically with those from Agents or Steps.

3. **Runtime Session Integration**
   - **Step Execution:** Each Step execution within a RuntimeSession can generate a Signal capturing the input, output, and any errors.
   - **Parent-Child Relationships:** These Signals are linked back to the originating Mission or Agent Signal.

### 4. Implementation Phases

**Phase 1: Core Signal Infrastructure**
- Create the `Signal` struct and enums.
- Implement database migrations to add the `signals` table.
- Develop basic Signal creation and query functions.

**Phase 2: System Integration**
- **Agents:** Update Agent logic to generate Signals during their action/reaction cycles.
- **Missions:** Instrument Mission execution flows to create and update Signals.
- **RuntimeSessions:** Integrate Signal generation during step execution and on error events.

**Phase 3: Observability Enhancements**
- Build APIs to query and filter Signals.
- Develop a rudimentary dashboard/log viewer for monitoring Signals in real-time.
- Integrate Signal correlation views to assist with debugging and auditing.

## Technical Considerations

1. **Propagation and Causation**
   - Maintain parent-child relationships between Signals for contextual tracing.
   - Use simple JSON key-value pairs to capture additional metadata.

2. **Performance Impact**
   - Batch Signal writes where possible to reduce IO pressure.
   - Employ appropriate indexing (e.g., timestamp and parent_signal_id).

3. **Storage and Retention**
   - Estimate the frequency of Signals and determine retention policies.
   - Consider table partitioning if event volume grows significantly.

## Migration Strategy

1. **Database**
   - Create the new `signals` table.
   - Apply necessary indexes.
   - No changes are required to existing tables.

2. **Code Updates**
   - Introduce Signal-related traits and functions across Agents, Jobs, and RuntimeSessions.
   - Gradually integrate Signal generation into key workflows with feature flags if needed.

3. **Testing**
   - Unit-test the Signal model.
   - Run integration tests to ensure Signals propagate correctly between services.
   - Conduct performance testing for Signal write and query operations.

## Future Considerations

1. **Export Capabilities**
   - Ability to export Signal logs for external analysis.
   - Integration with third-party monitoring systems if needed later.

2. **Advanced Features**
   - Complex correlation analysis (e.g., visual trace trees).
   - Sampling, throttling, or deduplication strategies for high-frequency Signals.

3. **Tooling and Analytics**
   - A dedicated UI dashboard for viewing and searching Signals.
   - Enhanced analytics to monitor system health and performance based on Signal data.

## Success Metrics

1. **Technical Metrics**
   - Latency of Signal creation and persistence.
   - Query response times for Signal-based filters.
   - Storage efficiency with the new schema.

2. **Business Metrics**
   - Reduction in debug time due to improved observability.
   - Faster detection and resolution of system issues.

3. **User Experience**
   - Clarity and usefulness of Signal logs and dashboards.
   - Overall satisfaction with system responsiveness and traceability.
